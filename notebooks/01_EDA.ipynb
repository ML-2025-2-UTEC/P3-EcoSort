{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc47add4",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df46ff",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fac692",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4900833",
   "metadata": {},
   "source": [
    "## 2. Configuración de Rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_base = Path(r'e:\\06. Sexto Ciclo\\01. Machine Learning\\07. Workspace\\16S03. Proyecto 03\\P3-EcoSort')\n",
    "ruta_train = ruta_base / 'data' / 'preprocessed' / 'train'\n",
    "ruta_val = ruta_base / 'data' / 'preprocessed' / 'val'\n",
    "ruta_figuras = ruta_base / 'result' / 'figures'\n",
    "\n",
    "ruta_figuras.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "clases = ['general', 'paper', 'plastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93e938",
   "metadata": {},
   "source": [
    "## 3. Estructura del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b8d08",
   "metadata": {},
   "source": [
    "### 3.1 Distribución de Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed933b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_imagenes(ruta):\n",
    "    conteo = {}\n",
    "    for clase in clases:\n",
    "        ruta_clase = ruta / clase\n",
    "        if ruta_clase.exists():\n",
    "            archivos = list(ruta_clase.glob('*'))\n",
    "            conteo[clase] = len([f for f in archivos if f.is_file()])\n",
    "        else:\n",
    "            conteo[clase] = 0\n",
    "    return conteo\n",
    "\n",
    "conteo_train = contar_imagenes(ruta_train)\n",
    "conteo_val = contar_imagenes(ruta_val)\n",
    "\n",
    "df_distribucion = pd.DataFrame({\n",
    "    'Clase': clases,\n",
    "    'Train': [conteo_train[c] for c in clases],\n",
    "    'Validación': [conteo_val[c] for c in clases],\n",
    "    'Total': [conteo_train[c] + conteo_val[c] for c in clases]\n",
    "})\n",
    "\n",
    "df_distribucion['Porcentaje Train (%)'] = (df_distribucion['Train'] / df_distribucion['Train'].sum() * 100).round(2)\n",
    "df_distribucion['Porcentaje Total (%)'] = (df_distribucion['Total'] / df_distribucion['Total'].sum() * 100).round(2)\n",
    "\n",
    "df_distribucion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1eb18",
   "metadata": {},
   "source": [
    "### 3.2 Visualización de Distribución de Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40588264",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].bar(df_distribucion['Clase'], df_distribucion['Train'], alpha=0.8, label='Train', color='#1f77b4')\n",
    "axes[0].bar(df_distribucion['Clase'], df_distribucion['Validación'], bottom=df_distribucion['Train'], \n",
    "           alpha=0.8, label='Validación', color='#ff7f0e')\n",
    "axes[0].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Número de Imágenes', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Distribución de Imágenes por Clase', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (clase, train, val) in enumerate(zip(df_distribucion['Clase'], df_distribucion['Train'], df_distribucion['Validación'])):\n",
    "    axes[0].text(i, train + val + 20, f'{train + val}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "colores = ['#2ecc71', '#e74c3c', '#3498db']\n",
    "axes[1].pie(df_distribucion['Total'], labels=df_distribucion['Clase'], autopct='%1.1f%%', \n",
    "           startangle=90, colors=colores, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Proporción de Clases en el Dataset Total', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '01_eda_01_distribucion_clases.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8482b26",
   "metadata": {},
   "source": [
    "### 3.3 Análisis de Tamaños y Resoluciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b74fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_dimensiones_imagenes(ruta, muestra=100):\n",
    "    dimensiones = []\n",
    "    aspectos = []\n",
    "    formatos = []\n",
    "    \n",
    "    for clase in clases:\n",
    "        ruta_clase = ruta / clase\n",
    "        archivos = list(ruta_clase.glob('*'))[:muestra]\n",
    "        \n",
    "        for archivo in archivos:\n",
    "            if archivo.is_file():\n",
    "                try:\n",
    "                    img = Image.open(archivo)\n",
    "                    ancho, alto = img.size\n",
    "                    dimensiones.append((ancho, alto))\n",
    "                    aspectos.append(ancho / alto)\n",
    "                    formatos.append(img.format)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return dimensiones, aspectos, formatos\n",
    "\n",
    "dimensiones_train, aspectos_train, formatos_train = analizar_dimensiones_imagenes(ruta_train, muestra=200)\n",
    "\n",
    "anchos = [d[0] for d in dimensiones_train]\n",
    "altos = [d[1] for d in dimensiones_train]\n",
    "\n",
    "df_dimensiones = pd.DataFrame({\n",
    "    'Métrica': ['Ancho Mínimo', 'Ancho Máximo', 'Ancho Promedio', 'Ancho Mediana',\n",
    "                'Alto Mínimo', 'Alto Máximo', 'Alto Promedio', 'Alto Mediana',\n",
    "                'Aspecto Mínimo', 'Aspecto Máximo', 'Aspecto Promedio'],\n",
    "    'Valor': [\n",
    "        np.min(anchos), np.max(anchos), np.mean(anchos), np.median(anchos),\n",
    "        np.min(altos), np.max(altos), np.mean(altos), np.median(altos),\n",
    "        np.min(aspectos_train), np.max(aspectos_train), np.mean(aspectos_train)\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_dimensiones['Valor'] = df_dimensiones['Valor'].round(2)\n",
    "df_dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efe58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatos_counter = Counter(formatos_train)\n",
    "df_formatos = pd.DataFrame(formatos_counter.items(), columns=['Formato', 'Cantidad'])\n",
    "df_formatos = df_formatos.sort_values('Cantidad', ascending=False)\n",
    "df_formatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e0116",
   "metadata": {},
   "source": [
    "### 3.4 Visualización de Dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].scatter(anchos, altos, alpha=0.5, s=30, c='#3498db')\n",
    "axes[0].set_xlabel('Ancho (píxeles)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Alto (píxeles)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Dispersión de Dimensiones de Imágenes', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(aspectos_train, bins=30, alpha=0.7, color='#e74c3c', edgecolor='black')\n",
    "axes[1].axvline(np.mean(aspectos_train), color='#2ecc71', linestyle='--', linewidth=2, label=f'Media: {np.mean(aspectos_train):.2f}')\n",
    "axes[1].set_xlabel('Relación de Aspecto (ancho/alto)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Frecuencia', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Distribución de Relación de Aspecto', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[2].bar(df_formatos['Formato'], df_formatos['Cantidad'], alpha=0.8, color='#9b59b6', edgecolor='black')\n",
    "axes[2].set_xlabel('Formato de Imagen', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Cantidad', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title('Distribución de Formatos de Imagen', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (formato, cantidad) in enumerate(zip(df_formatos['Formato'], df_formatos['Cantidad'])):\n",
    "    axes[2].text(i, cantidad + 5, str(cantidad), ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '01_eda_02_dimensiones_imagenes.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3042ec5",
   "metadata": {},
   "source": [
    "## 4. Visualización Exploratoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd905bb",
   "metadata": {},
   "source": [
    "### 4.1 Ejemplos Representativos de Cada Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_ejemplos_clase(ruta, clase, num_ejemplos=8):\n",
    "    ruta_clase = ruta / clase\n",
    "    archivos = list(ruta_clase.glob('*'))[:num_ejemplos]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle(f'Ejemplos Representativos - Clase: {clase.upper()}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, archivo in enumerate(archivos):\n",
    "        if archivo.is_file():\n",
    "            img = Image.open(archivo)\n",
    "            ax = axes[idx // 4, idx % 4]\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f'{img.size[0]}×{img.size[1]} px', fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ruta_figuras / f'01_eda_03_ejemplos_{clase}.svg', format='svg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "for clase in clases:\n",
    "    mostrar_ejemplos_clase(ruta_train, clase, num_ejemplos=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910334c8",
   "metadata": {},
   "source": [
    "### 4.2 Análisis de Variabilidad Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc929440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_variabilidad(ruta, muestra=50):\n",
    "    estadisticas = []\n",
    "    \n",
    "    for clase in clases:\n",
    "        ruta_clase = ruta / clase\n",
    "        archivos = list(ruta_clase.glob('*'))[:muestra]\n",
    "        \n",
    "        brillos = []\n",
    "        contrastes = []\n",
    "        saturaciones = []\n",
    "        \n",
    "        for archivo in archivos:\n",
    "            if archivo.is_file():\n",
    "                try:\n",
    "                    img = cv2.imread(str(archivo))\n",
    "                    if img is not None:\n",
    "                        img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                        \n",
    "                        brillo = np.mean(img_hsv[:, :, 2])\n",
    "                        brillos.append(brillo)\n",
    "                        \n",
    "                        contraste = np.std(img)\n",
    "                        contrastes.append(contraste)\n",
    "                        \n",
    "                        saturacion = np.mean(img_hsv[:, :, 1])\n",
    "                        saturaciones.append(saturacion)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        estadisticas.append({\n",
    "            'Clase': clase,\n",
    "            'Brillo Promedio': np.mean(brillos) if brillos else 0,\n",
    "            'Brillo Std': np.std(brillos) if brillos else 0,\n",
    "            'Contraste Promedio': np.mean(contrastes) if contrastes else 0,\n",
    "            'Contraste Std': np.std(contrastes) if contrastes else 0,\n",
    "            'Saturación Promedio': np.mean(saturaciones) if saturaciones else 0,\n",
    "            'Saturación Std': np.std(saturaciones) if saturaciones else 0\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(estadisticas)\n",
    "\n",
    "df_variabilidad = analizar_variabilidad(ruta_train, muestra=100)\n",
    "df_variabilidad = df_variabilidad.round(2)\n",
    "df_variabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b94330",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "x = np.arange(len(clases))\n",
    "ancho_barra = 0.35\n",
    "\n",
    "axes[0].bar(x - ancho_barra/2, df_variabilidad['Brillo Promedio'], ancho_barra, \n",
    "           label='Promedio', alpha=0.8, color='#f39c12', edgecolor='black')\n",
    "axes[0].bar(x + ancho_barra/2, df_variabilidad['Brillo Std'], ancho_barra, \n",
    "           label='Desviación Estándar', alpha=0.8, color='#e67e22', edgecolor='black')\n",
    "axes[0].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Valor', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Análisis de Brillo por Clase', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(clases)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[1].bar(x - ancho_barra/2, df_variabilidad['Contraste Promedio'], ancho_barra, \n",
    "           label='Promedio', alpha=0.8, color='#3498db', edgecolor='black')\n",
    "axes[1].bar(x + ancho_barra/2, df_variabilidad['Contraste Std'], ancho_barra, \n",
    "           label='Desviación Estándar', alpha=0.8, color='#2980b9', edgecolor='black')\n",
    "axes[1].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Valor', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Análisis de Contraste por Clase', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(clases)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[2].bar(x - ancho_barra/2, df_variabilidad['Saturación Promedio'], ancho_barra, \n",
    "           label='Promedio', alpha=0.8, color='#e74c3c', edgecolor='black')\n",
    "axes[2].bar(x + ancho_barra/2, df_variabilidad['Saturación Std'], ancho_barra, \n",
    "           label='Desviación Estándar', alpha=0.8, color='#c0392b', edgecolor='black')\n",
    "axes[2].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Valor', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title('Análisis de Saturación por Clase', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(clases)\n",
    "axes[2].legend(fontsize=10)\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '01_eda_06_variabilidad_visual.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f1d25",
   "metadata": {},
   "source": [
    "## 5. Análisis Cuantitativo de Clases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294307a",
   "metadata": {},
   "source": [
    "### 5.1 Medición de Desbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6215ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = df_distribucion['Train'].sum()\n",
    "clase_mayoritaria = df_distribucion['Train'].max()\n",
    "clase_minoritaria = df_distribucion['Train'].min()\n",
    "\n",
    "ratio_desbalance = clase_mayoritaria / clase_minoritaria\n",
    "\n",
    "df_desbalance = pd.DataFrame({\n",
    "    'Métrica': ['Total Train', 'Clase Mayoritaria', 'Clase Minoritaria', 'Ratio de Desbalance'],\n",
    "    'Valor': [total_train, clase_mayoritaria, clase_minoritaria, ratio_desbalance]\n",
    "})\n",
    "\n",
    "df_desbalance['Valor'] = df_desbalance['Valor'].round(2)\n",
    "df_desbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colores_barra = ['#2ecc71' if x == clase_mayoritaria else '#e74c3c' if x == clase_minoritaria else '#3498db' \n",
    "                 for x in df_distribucion['Train']]\n",
    "\n",
    "bars = ax.bar(df_distribucion['Clase'], df_distribucion['Train'], alpha=0.8, color=colores_barra, edgecolor='black')\n",
    "\n",
    "ax.axhline(y=total_train/3, color='orange', linestyle='--', linewidth=2, label=f'Balance Ideal: {int(total_train/3)}')\n",
    "\n",
    "ax.set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Número de Imágenes', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Desbalance de Clases (Ratio: {ratio_desbalance:.2f}:1)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (clase, cantidad) in enumerate(zip(df_distribucion['Clase'], df_distribucion['Train'])):\n",
    "    ax.text(i, cantidad + 20, f'{cantidad}\\n({df_distribucion[\"Porcentaje Train (%)\"].iloc[i]}%)', \n",
    "           ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '01_eda_07_desbalance_clases.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3360d",
   "metadata": {},
   "source": [
    "## 6. Detección de Problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce94fca",
   "metadata": {},
   "source": [
    "### 6.1 Verificación de Imágenes Corruptas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f018bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_imagenes_corruptas(ruta):\n",
    "    corruptas = []\n",
    "    totales = 0\n",
    "    \n",
    "    for clase in clases:\n",
    "        ruta_clase = ruta / clase\n",
    "        archivos = list(ruta_clase.glob('*'))\n",
    "        \n",
    "        for archivo in archivos:\n",
    "            if archivo.is_file():\n",
    "                totales += 1\n",
    "                try:\n",
    "                    img = Image.open(archivo)\n",
    "                    img.verify()\n",
    "                except:\n",
    "                    corruptas.append({'Clase': clase, 'Archivo': archivo.name})\n",
    "    \n",
    "    return corruptas, totales\n",
    "\n",
    "corruptas_train, total_train_check = verificar_imagenes_corruptas(ruta_train)\n",
    "corruptas_val, total_val_check = verificar_imagenes_corruptas(ruta_val)\n",
    "\n",
    "df_corruptas = pd.DataFrame({\n",
    "    'Conjunto': ['Train', 'Validación', 'Total'],\n",
    "    'Imágenes Totales': [total_train_check, total_val_check, total_train_check + total_val_check],\n",
    "    'Imágenes Corruptas': [len(corruptas_train), len(corruptas_val), len(corruptas_train) + len(corruptas_val)],\n",
    "    'Porcentaje Corruptas (%)': [\n",
    "        (len(corruptas_train) / total_train_check * 100) if total_train_check > 0 else 0,\n",
    "        (len(corruptas_val) / total_val_check * 100) if total_val_check > 0 else 0,\n",
    "        ((len(corruptas_train) + len(corruptas_val)) / (total_train_check + total_val_check) * 100) \n",
    "        if (total_train_check + total_val_check) > 0 else 0\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_corruptas['Porcentaje Corruptas (%)'] = df_corruptas['Porcentaje Corruptas (%)'].round(2)\n",
    "df_corruptas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47ef85",
   "metadata": {},
   "source": [
    "### 6.2 Verificación de Dimensiones Inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3248f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_dimensiones_extremas(ruta, umbral_min=50, umbral_max=5000):\n",
    "    problematicas = []\n",
    "    \n",
    "    for clase in clases:\n",
    "        ruta_clase = ruta / clase\n",
    "        archivos = list(ruta_clase.glob('*'))\n",
    "        \n",
    "        for archivo in archivos:\n",
    "            if archivo.is_file():\n",
    "                try:\n",
    "                    img = Image.open(archivo)\n",
    "                    ancho, alto = img.size\n",
    "                    \n",
    "                    if ancho < umbral_min or alto < umbral_min or ancho > umbral_max or alto > umbral_max:\n",
    "                        problematicas.append({\n",
    "                            'Clase': clase,\n",
    "                            'Archivo': archivo.name,\n",
    "                            'Ancho': ancho,\n",
    "                            'Alto': alto,\n",
    "                            'Problema': 'Muy pequeña' if (ancho < umbral_min or alto < umbral_min) else 'Muy grande'\n",
    "                        })\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return problematicas\n",
    "\n",
    "problematicas_train = verificar_dimensiones_extremas(ruta_train)\n",
    "problematicas_val = verificar_dimensiones_extremas(ruta_val)\n",
    "\n",
    "df_problemas = pd.DataFrame({\n",
    "    'Conjunto': ['Train', 'Validación', 'Total'],\n",
    "    'Dimensiones Extremas': [len(problematicas_train), len(problematicas_val), \n",
    "                            len(problematicas_train) + len(problematicas_val)]\n",
    "})\n",
    "\n",
    "df_problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5759dc",
   "metadata": {},
   "source": [
    "## 7. Conclusiones del EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e12863f",
   "metadata": {},
   "source": [
    "### Hallazgos Principales:\n",
    "\n",
    "**1. Distribución del Dataset:**\n",
    "- El dataset contiene 3 clases: general, paper y plastic\n",
    "- Existe un desbalance notable entre las clases\n",
    "- La clase plastic es la minoritaria, lo que requerirá técnicas de balanceo\n",
    "\n",
    "**2. Características de las Imágenes:**\n",
    "- Las imágenes tienen dimensiones variables y diversos formatos\n",
    "- Se requiere normalización de tamaños para el modelado\n",
    "- La variabilidad en brillo, contraste y saturación sugiere necesidad de data augmentation\n",
    "\n",
    "**3. Calidad del Dataset:**\n",
    "- No se detectaron imágenes corruptas significativas\n",
    "- Las dimensiones son generalmente consistentes\n",
    "- El dataset está en buenas condiciones para el entrenamiento\n",
    "\n",
    "**4. Recomendaciones para Feature Engineering:**\n",
    "- Aplicar data augmentation para balancear clases y aumentar variabilidad\n",
    "- Normalizar dimensiones a tamaño fijo (224x224 o 128x128)\n",
    "- Extraer características HOG y de color para modelos no neuronales\n",
    "- Considerar técnicas de oversampling para la clase minoritaria\n",
    "- Aplicar normalización de píxeles para mejorar convergencia de modelos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "06C_Machine_15S02_Proyecto03",
   "language": "python",
   "name": "06c_machine_15s02_proyecto03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
