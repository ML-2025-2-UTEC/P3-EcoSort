{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba98917",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb82938",
   "metadata": {},
   "source": [
    "## 2. Configuración de Rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5833d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_base = Path(r'e:\\06. Sexto Ciclo\\01. Machine Learning\\07. Workspace\\16S03. Proyecto 03\\P3-EcoSort')\n",
    "ruta_train = ruta_base / 'data' / 'preprocessed' / 'train'\n",
    "ruta_val = ruta_base / 'data' / 'preprocessed' / 'val'\n",
    "ruta_features = ruta_base / 'result' / 'features'\n",
    "ruta_figuras = ruta_base / 'result' / 'figures'\n",
    "\n",
    "ruta_features.mkdir(parents=True, exist_ok=True)\n",
    "ruta_figuras.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "clases = ['general', 'paper', 'plastic']\n",
    "mapeo_clases = {'general': 0, 'paper': 1, 'plastic': 2}\n",
    "tamanio_imagen = (128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa0230",
   "metadata": {},
   "source": [
    "## 3. Carga y Normalización de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bad517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_imagenes(ruta, tamanio):\n",
    "    imagenes = []\n",
    "    etiquetas = []\n",
    "    rutas_archivos = []\n",
    "    \n",
    "    for clase in clases:\n",
    "        ruta_clase = ruta / clase\n",
    "        archivos = list(ruta_clase.glob('*'))\n",
    "        \n",
    "        for archivo in tqdm(archivos, desc=f'Cargando {clase}'):\n",
    "            if archivo.is_file():\n",
    "                try:\n",
    "                    img = Image.open(archivo)\n",
    "                    img = img.convert('RGB')\n",
    "                    img = img.resize(tamanio)\n",
    "                    img_array = np.array(img) / 255.0\n",
    "                    \n",
    "                    imagenes.append(img_array)\n",
    "                    etiquetas.append(mapeo_clases[clase])\n",
    "                    rutas_archivos.append(str(archivo))\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "    \n",
    "    return np.array(imagenes), np.array(etiquetas), rutas_archivos\n",
    "\n",
    "X_train, y_train, rutas_train = cargar_imagenes(ruta_train, tamanio_imagen)\n",
    "X_val, y_val, rutas_val = cargar_imagenes(ruta_val, tamanio_imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203dd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carga = pd.DataFrame({\n",
    "    'Conjunto': ['Train', 'Validación'],\n",
    "    'Cantidad Imágenes': [len(X_train), len(X_val)],\n",
    "    'Dimensiones': [X_train.shape, X_val.shape],\n",
    "    'Rango Valores': [f'[{X_train.min():.2f}, {X_train.max():.2f}]', \n",
    "                      f'[{X_val.min():.2f}, {X_val.max():.2f}]']\n",
    "})\n",
    "\n",
    "df_carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c5bd8",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244eac3",
   "metadata": {},
   "source": [
    "### 4.1 Funciones de Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotar_imagen(img, angulo):\n",
    "    h, w = img.shape[:2]\n",
    "    centro = (w // 2, h // 2)\n",
    "    matriz = cv2.getRotationMatrix2D(centro, angulo, 1.0)\n",
    "    return cv2.warpAffine(img, matriz, (w, h))\n",
    "\n",
    "def voltear_horizontal(img):\n",
    "    return cv2.flip(img, 1)\n",
    "\n",
    "def voltear_vertical(img):\n",
    "    return cv2.flip(img, 0)\n",
    "\n",
    "def ajustar_brillo(img, factor):\n",
    "    img_ajustada = img * factor\n",
    "    return np.clip(img_ajustada, 0, 1)\n",
    "\n",
    "def ajustar_contraste(img, factor):\n",
    "    media = np.mean(img)\n",
    "    img_ajustada = (img - media) * factor + media\n",
    "    return np.clip(img_ajustada, 0, 1)\n",
    "\n",
    "def aplicar_zoom(img, factor):\n",
    "    h, w = img.shape[:2]\n",
    "    nuevo_h, nuevo_w = int(h * factor), int(w * factor)\n",
    "    img_zoom = cv2.resize(img, (nuevo_w, nuevo_h))\n",
    "    \n",
    "    if factor > 1:\n",
    "        inicio_h = (nuevo_h - h) // 2\n",
    "        inicio_w = (nuevo_w - w) // 2\n",
    "        return img_zoom[inicio_h:inicio_h+h, inicio_w:inicio_w+w]\n",
    "    else:\n",
    "        resultado = np.zeros_like(img)\n",
    "        inicio_h = (h - nuevo_h) // 2\n",
    "        inicio_w = (w - nuevo_w) // 2\n",
    "        resultado[inicio_h:inicio_h+nuevo_h, inicio_w:inicio_w+nuevo_w] = img_zoom\n",
    "        return resultado\n",
    "\n",
    "def trasladar_imagen(img, dx, dy):\n",
    "    h, w = img.shape[:2]\n",
    "    matriz = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    return cv2.warpAffine(img, matriz, (w, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d42aa0",
   "metadata": {},
   "source": [
    "### 4.2 Generación de Dataset Aumentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c7072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentar_dataset(X, y, objetivo=10000):\n",
    "    X_aug = list(X)\n",
    "    y_aug = list(y)\n",
    "    \n",
    "    transformaciones = [\n",
    "        lambda img: rotar_imagen(img, 15),\n",
    "        lambda img: rotar_imagen(img, -15),\n",
    "        lambda img: rotar_imagen(img, 30),\n",
    "        lambda img: voltear_horizontal(img),\n",
    "        lambda img: voltear_vertical(img),\n",
    "        lambda img: ajustar_brillo(img, 1.2),\n",
    "        lambda img: ajustar_brillo(img, 0.8),\n",
    "        lambda img: ajustar_contraste(img, 1.3),\n",
    "        lambda img: ajustar_contraste(img, 0.7),\n",
    "        lambda img: aplicar_zoom(img, 1.2),\n",
    "        lambda img: aplicar_zoom(img, 0.8),\n",
    "        lambda img: trasladar_imagen(img, 10, 10),\n",
    "        lambda img: trasladar_imagen(img, -10, -10)\n",
    "    ]\n",
    "    \n",
    "    while len(X_aug) < objetivo:\n",
    "        idx = np.random.randint(0, len(X))\n",
    "        img = X[idx]\n",
    "        etiqueta = y[idx]\n",
    "        \n",
    "        num_trans = np.random.randint(1, 4)\n",
    "        trans_seleccionadas = np.random.choice(transformaciones, num_trans, replace=False)\n",
    "        \n",
    "        img_aug = img.copy()\n",
    "        for trans in trans_seleccionadas:\n",
    "            img_aug = trans(img_aug)\n",
    "        \n",
    "        X_aug.append(img_aug)\n",
    "        y_aug.append(etiqueta)\n",
    "        \n",
    "        if len(X_aug) % 1000 == 0:\n",
    "            tqdm.write(f'Imágenes aumentadas: {len(X_aug)}/{objetivo}')\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)\n",
    "\n",
    "X_train_aug, y_train_aug = augmentar_dataset(X_train, y_train, objetivo=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmentation = pd.DataFrame({\n",
    "    'Conjunto': ['Original Train', 'Aumentado Train', 'Validación'],\n",
    "    'Cantidad': [len(X_train), len(X_train_aug), len(X_val)],\n",
    "    'Incremento': ['Base', f'+{len(X_train_aug) - len(X_train)}', 'Sin cambios']\n",
    "})\n",
    "\n",
    "df_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5758537",
   "metadata": {},
   "source": [
    "### 4.3 Visualización de Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ejemplo = 0\n",
    "img_original = X_train[idx_ejemplo]\n",
    "\n",
    "ejemplos = [\n",
    "    ('Original', img_original),\n",
    "    ('Rotación 15°', rotar_imagen(img_original, 15)),\n",
    "    ('Volteo Horizontal', voltear_horizontal(img_original)),\n",
    "    ('Brillo +20%', ajustar_brillo(img_original, 1.2)),\n",
    "    ('Contraste +30%', ajustar_contraste(img_original, 1.3)),\n",
    "    ('Zoom 1.2x', aplicar_zoom(img_original, 1.2))\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Ejemplos de Data Augmentation', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (titulo, img) in enumerate(ejemplos):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(titulo, fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '02_fe_01_augmentation_ejemplos.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f2a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "conteo_original = np.bincount(y_train)\n",
    "conteo_aumentado = np.bincount(y_train_aug)\n",
    "\n",
    "x = np.arange(len(clases))\n",
    "ancho_barra = 0.35\n",
    "\n",
    "axes[0].bar(x - ancho_barra/2, conteo_original, ancho_barra, label='Original', alpha=0.8, color='#3498db', edgecolor='black')\n",
    "axes[0].bar(x + ancho_barra/2, conteo_aumentado, ancho_barra, label='Aumentado', alpha=0.8, color='#2ecc71', edgecolor='black')\n",
    "axes[0].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Cantidad', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Comparación: Original vs Aumentado', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(clases)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "porcentajes_aumentado = conteo_aumentado / conteo_aumentado.sum() * 100\n",
    "colores = ['#2ecc71', '#e74c3c', '#3498db']\n",
    "axes[1].pie(porcentajes_aumentado, labels=clases, autopct='%1.1f%%', startangle=90, \n",
    "           colors=colores, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Distribución Dataset Aumentado', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '02_fe_02_distribucion_aumentada.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e00b7",
   "metadata": {},
   "source": [
    "## 5. Extracción de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b34d60",
   "metadata": {},
   "source": [
    "### 5.1 Extracción HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f431584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_hog(imagenes):\n",
    "    caracteristicas_hog = []\n",
    "    \n",
    "    for img in tqdm(imagenes, desc='Extrayendo HOG'):\n",
    "        img_gris = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        features = hog(img_gris, orientations=9, pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2), visualize=False, feature_vector=True)\n",
    "        \n",
    "        caracteristicas_hog.append(features)\n",
    "    \n",
    "    return np.array(caracteristicas_hog)\n",
    "\n",
    "hog_train = extraer_hog(X_train_aug)\n",
    "hog_val = extraer_hog(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hog = pd.DataFrame({\n",
    "    'Conjunto': ['Train Aumentado', 'Validación'],\n",
    "    'Dimensión HOG': [hog_train.shape, hog_val.shape],\n",
    "    'Características por Imagen': [hog_train.shape[1], hog_val.shape[1]]\n",
    "})\n",
    "\n",
    "df_hog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63e476",
   "metadata": {},
   "source": [
    "### 5.2 Visualización de HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5934fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_vis = 0\n",
    "img_ejemplo = X_train_aug[idx_vis]\n",
    "img_gris = cv2.cvtColor((img_ejemplo * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "features, hog_image = hog(img_gris, orientations=9, pixels_per_cell=(8, 8),\n",
    "                         cells_per_block=(2, 2), visualize=True, feature_vector=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(img_ejemplo)\n",
    "axes[0].set_title('Imagen Original (RGB)', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(img_gris, cmap='gray')\n",
    "axes[1].set_title('Imagen en Escala de Grises', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(hog_image, cmap='gray')\n",
    "axes[2].set_title('Visualización HOG', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '02_fe_03_hog_visualizacion.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ae97b",
   "metadata": {},
   "source": [
    "### 5.3 Extracción de Características de Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_caracteristicas_color(imagenes):\n",
    "    caracteristicas_color = []\n",
    "    \n",
    "    for img in tqdm(imagenes, desc='Extrayendo Color'):\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        \n",
    "        hist_r = cv2.calcHist([img_uint8], [0], None, [32], [0, 256]).flatten()\n",
    "        hist_g = cv2.calcHist([img_uint8], [1], None, [32], [0, 256]).flatten()\n",
    "        hist_b = cv2.calcHist([img_uint8], [2], None, [32], [0, 256]).flatten()\n",
    "        \n",
    "        img_hsv = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2HSV)\n",
    "        hist_h = cv2.calcHist([img_hsv], [0], None, [32], [0, 180]).flatten()\n",
    "        hist_s = cv2.calcHist([img_hsv], [1], None, [32], [0, 256]).flatten()\n",
    "        hist_v = cv2.calcHist([img_hsv], [2], None, [32], [0, 256]).flatten()\n",
    "        \n",
    "        media_r, media_g, media_b = np.mean(img, axis=(0, 1))\n",
    "        std_r, std_g, std_b = np.std(img, axis=(0, 1))\n",
    "        \n",
    "        momentos_color = [media_r, media_g, media_b, std_r, std_g, std_b]\n",
    "        \n",
    "        features = np.concatenate([hist_r, hist_g, hist_b, hist_h, hist_s, hist_v, momentos_color])\n",
    "        caracteristicas_color.append(features)\n",
    "    \n",
    "    return np.array(caracteristicas_color)\n",
    "\n",
    "color_train = extraer_caracteristicas_color(X_train_aug)\n",
    "color_val = extraer_caracteristicas_color(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1acf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_color = pd.DataFrame({\n",
    "    'Conjunto': ['Train Aumentado', 'Validación'],\n",
    "    'Dimensión Color': [color_train.shape, color_val.shape],\n",
    "    'Características por Imagen': [color_train.shape[1], color_val.shape[1]]\n",
    "})\n",
    "\n",
    "df_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26ac7a",
   "metadata": {},
   "source": [
    "### 5.4 Fusión de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.concatenate([hog_train, color_train], axis=1)\n",
    "features_val = np.concatenate([hog_val, color_val], axis=1)\n",
    "\n",
    "df_fusion = pd.DataFrame({\n",
    "    'Conjunto': ['Train Aumentado', 'Validación'],\n",
    "    'Dimensión HOG': [hog_train.shape[1], hog_val.shape[1]],\n",
    "    'Dimensión Color': [color_train.shape[1], color_val.shape[1]],\n",
    "    'Dimensión Total': [features_train.shape[1], features_val.shape[1]],\n",
    "    'Shape Final': [features_train.shape, features_val.shape]\n",
    "})\n",
    "\n",
    "df_fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19d8f9",
   "metadata": {},
   "source": [
    "## 6. Reducción Dimensional con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_train_scaled = scaler.fit_transform(features_train)\n",
    "features_val_scaled = scaler.transform(features_val)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "features_train_pca = pca.fit_transform(features_train_scaled)\n",
    "features_val_pca = pca.transform(features_val_scaled)\n",
    "\n",
    "varianza_explicada = pca.explained_variance_ratio_\n",
    "varianza_acumulada = np.cumsum(varianza_explicada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame({\n",
    "    'Métrica': ['Componentes Originales', 'Componentes PCA', 'Reducción (%)', \n",
    "                'Varianza Explicada (%)', 'Primera Componente (%)'],\n",
    "    'Valor': [\n",
    "        features_train.shape[1],\n",
    "        features_train_pca.shape[1],\n",
    "        ((features_train.shape[1] - features_train_pca.shape[1]) / features_train.shape[1] * 100),\n",
    "        (varianza_acumulada[-1] * 100),\n",
    "        (varianza_explicada[0] * 100)\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_pca['Valor'] = df_pca['Valor'].round(2)\n",
    "df_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd762a",
   "metadata": {},
   "source": [
    "### 6.1 Visualización de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0453a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].plot(range(1, len(varianza_explicada) + 1), varianza_acumulada * 100, \n",
    "            marker='o', linestyle='-', linewidth=2, markersize=4, color='#3498db')\n",
    "axes[0].axhline(y=95, color='#e74c3c', linestyle='--', linewidth=2, label='95% Varianza')\n",
    "axes[0].axvline(x=features_train_pca.shape[1], color='#2ecc71', linestyle='--', \n",
    "               linewidth=2, label=f'Componentes: {features_train_pca.shape[1]}')\n",
    "axes[0].set_xlabel('Número de Componentes', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Varianza Explicada Acumulada (%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Varianza Explicada por PCA', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "top_n = 20\n",
    "axes[1].bar(range(1, top_n + 1), varianza_explicada[:top_n] * 100, \n",
    "           alpha=0.8, color='#9b59b6', edgecolor='black')\n",
    "axes[1].set_xlabel('Componente Principal', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Varianza Explicada (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title(f'Top {top_n} Componentes Principales', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '02_fe_04_pca_varianza.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605d66a",
   "metadata": {},
   "source": [
    "### 6.2 Visualización 2D de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d = PCA(n_components=2)\n",
    "features_train_2d = pca_2d.fit_transform(features_train_scaled)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colores_scatter = ['#2ecc71', '#e74c3c', '#3498db']\n",
    "for idx, clase in enumerate(clases):\n",
    "    mascara = y_train_aug == idx\n",
    "    ax.scatter(features_train_2d[mascara, 0], features_train_2d[mascara, 1], \n",
    "              c=colores_scatter[idx], label=clase, alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% varianza)', \n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% varianza)', \n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.set_title('Visualización 2D de Características con PCA', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '02_fe_05_pca_2d.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f2abe",
   "metadata": {},
   "source": [
    "## 7. Validación con Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ef3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_logistic = LogisticRegression(max_iter=1000, random_state=42)\n",
    "modelo_logistic.fit(features_train_pca, y_train_aug)\n",
    "\n",
    "y_pred_train = modelo_logistic.predict(features_train_pca)\n",
    "y_pred_val = modelo_logistic.predict(features_val_pca)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train_aug, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validacion = pd.DataFrame({\n",
    "    'Conjunto': ['Train', 'Validación'],\n",
    "    'Accuracy': [accuracy_train, accuracy_val]\n",
    "})\n",
    "\n",
    "df_validacion['Accuracy'] = df_validacion['Accuracy'].round(4)\n",
    "df_validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52163880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=clases, yticklabels=clases, \n",
    "           cbar_kws={'label': 'Cantidad'}, linewidths=2, linecolor='black', ax=ax)\n",
    "ax.set_xlabel('Predicción', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Valor Real', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Matriz de Confusión - Validación Logistic Regression\\nAccuracy: {accuracy_val:.4f}', \n",
    "            fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '02_fe_06_confusion_matrix.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f394d4",
   "metadata": {},
   "source": [
    "## 8. Almacenamiento de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(ruta_features / 'X_train_imagenes.npy', X_train_aug)\n",
    "np.save(ruta_features / 'y_train.npy', y_train_aug)\n",
    "np.save(ruta_features / 'X_val_imagenes.npy', X_val)\n",
    "np.save(ruta_features / 'y_val.npy', y_val)\n",
    "\n",
    "np.save(ruta_features / 'features_train_hog.npy', hog_train)\n",
    "np.save(ruta_features / 'features_val_hog.npy', hog_val)\n",
    "\n",
    "np.save(ruta_features / 'features_train_color.npy', color_train)\n",
    "np.save(ruta_features / 'features_val_color.npy', color_val)\n",
    "\n",
    "np.save(ruta_features / 'features_train_combinadas.npy', features_train)\n",
    "np.save(ruta_features / 'features_val_combinadas.npy', features_val)\n",
    "\n",
    "np.save(ruta_features / 'features_train_pca.npy', features_train_pca)\n",
    "np.save(ruta_features / 'features_val_pca.npy', features_val_pca)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, ruta_features / 'scaler.pkl')\n",
    "joblib.dump(pca, ruta_features / 'pca.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_guardados = list(ruta_features.glob('*'))\n",
    "\n",
    "df_archivos = pd.DataFrame({\n",
    "    'Archivo': [f.name for f in archivos_guardados],\n",
    "    'Tamaño (MB)': [(f.stat().st_size / (1024 * 1024)) for f in archivos_guardados]\n",
    "})\n",
    "\n",
    "df_archivos['Tamaño (MB)'] = df_archivos['Tamaño (MB)'].round(2)\n",
    "df_archivos = df_archivos.sort_values('Tamaño (MB)', ascending=False)\n",
    "df_archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55daffb1",
   "metadata": {},
   "source": [
    "## 9. Resumen de Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416478ce",
   "metadata": {},
   "source": [
    "### Proceso Completado:\n",
    "\n",
    "**1. Normalización:**\n",
    "- Todas las imágenes redimensionadas a 128×128 píxeles\n",
    "- Valores normalizados al rango [0, 1]\n",
    "- Conversión uniforme a RGB\n",
    "\n",
    "**2. Data Augmentation:**\n",
    "- Dataset aumentado a más de 10,000 imágenes de entrenamiento\n",
    "- Transformaciones aplicadas: rotación, volteo, brillo, contraste, zoom, traslación\n",
    "- Distribución balanceada entre clases\n",
    "\n",
    "**3. Extracción de Características:**\n",
    "- **HOG**: Captura gradientes y formas en escala de grises\n",
    "- **Color**: Histogramas RGB y HSV, más momentos estadísticos\n",
    "- **Fusión**: Combinación completa de HOG + Color\n",
    "\n",
    "**4. Reducción Dimensional:**\n",
    "- PCA aplicado preservando 95% de varianza\n",
    "- Reducción significativa de dimensiones\n",
    "- Características listas para SVM y Logistic Regression\n",
    "\n",
    "**5. Validación:**\n",
    "- Logistic Regression simple confirma que las características son discriminativas\n",
    "- Accuracy de validación indica separabilidad entre clases\n",
    "\n",
    "**6. Almacenamiento:**\n",
    "- Todas las matrices de características guardadas en result/features/\n",
    "- Listas para uso directo en entrenamiento de modelos\n",
    "- Scaler y PCA guardados para reproducibilidad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "06C_Machine_15S02_Proyecto03",
   "language": "python",
   "name": "06c_machine_15s02_proyecto03"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
