{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9570f0",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc921ab",
   "metadata": {},
   "source": [
    "## 2. Configuración de Rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_base = Path(r'e:\\06. Sexto Ciclo\\01. Machine Learning\\07. Workspace\\16S03. Proyecto 03\\P3-EcoSort')\n",
    "ruta_features = ruta_base / 'result' / 'features'\n",
    "ruta_modelos = ruta_base / 'result' / 'models'\n",
    "ruta_figuras = ruta_base / 'result' / 'figures'\n",
    "\n",
    "clases = ['general', 'paper', 'plastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad4fca9",
   "metadata": {},
   "source": [
    "## 3. Carga de Datos y Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b88063",
   "metadata": {},
   "source": [
    "### 3.1 Carga de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8072a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_img = np.load(ruta_features / 'X_val_imagenes.npy')\n",
    "y_val = np.load(ruta_features / 'y_val.npy')\n",
    "X_val_pca = np.load(ruta_features / 'features_val_pca.npy')\n",
    "\n",
    "df_datos = pd.DataFrame({\n",
    "    'Dataset': ['Validación Imágenes', 'Validación PCA'],\n",
    "    'Shape': [X_val_img.shape, X_val_pca.shape],\n",
    "    'Etiquetas': [len(y_val), len(y_val)]\n",
    "})\n",
    "\n",
    "df_datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd037c",
   "metadata": {},
   "source": [
    "### 3.2 Carga de Modelos y Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0511f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lr = joblib.load(ruta_modelos / 'logistic_regression.pkl')\n",
    "metricas_lr = joblib.load(ruta_modelos / 'logistic_regression_metricas.pkl')\n",
    "\n",
    "modelo_svm = joblib.load(ruta_modelos / 'svm.pkl')\n",
    "metricas_svm = joblib.load(ruta_modelos / 'svm_metricas.pkl')\n",
    "\n",
    "historial_cnn = joblib.load(ruta_modelos / 'cnn_historial.pkl')\n",
    "metricas_cnn = joblib.load(ruta_modelos / 'cnn_metricas.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b73c7f",
   "metadata": {},
   "source": [
    "### 3.3 Reconstrucción del Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Clasificador(nn.Module):\n",
    "    def __init__(self, num_clases=3, dropout=0.5):\n",
    "        super(CNN_Clasificador, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * 16 * 16, 512)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(128, num_clases)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "modelo_cnn = CNN_Clasificador(num_clases=3, dropout=0.5).to(device)\n",
    "modelo_cnn.load_state_dict(torch.load(ruta_modelos / 'cnn_model.pth'))\n",
    "modelo_cnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ecc9f",
   "metadata": {},
   "source": [
    "## 4. Comparación de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparacion = pd.DataFrame({\n",
    "    'Modelo': ['Logistic Regression', 'SVM', 'CNN'],\n",
    "    'F1 Macro Train': [\n",
    "        metricas_lr['f1_macro_train'],\n",
    "        metricas_svm['f1_macro_train'],\n",
    "        metricas_cnn['f1_macro_train']\n",
    "    ],\n",
    "    'F1 Macro Val': [\n",
    "        metricas_lr['f1_macro_val'],\n",
    "        metricas_svm['f1_macro_val'],\n",
    "        metricas_cnn['f1_macro_val']\n",
    "    ],\n",
    "    'F1 Micro Val': [\n",
    "        metricas_lr['f1_micro_val'],\n",
    "        metricas_svm['f1_micro_val'],\n",
    "        metricas_cnn['f1_micro_val']\n",
    "    ],\n",
    "    'AUC-PR Val': [\n",
    "        metricas_lr['auc_pr_macro_val'],\n",
    "        metricas_svm['auc_pr_macro_val'],\n",
    "        metricas_cnn['auc_pr_macro_val']\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_comparacion['Overfitting'] = (df_comparacion['F1 Macro Train'] - df_comparacion['F1 Macro Val']).abs()\n",
    "df_comparacion = df_comparacion.round(4)\n",
    "\n",
    "df_comparacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac891a8",
   "metadata": {},
   "source": [
    "### 4.1 Visualización Comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cce205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "modelos = df_comparacion['Modelo']\n",
    "colores = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "\n",
    "axes[0, 0].bar(modelos, df_comparacion['F1 Macro Val'], alpha=0.8, color=colores, edgecolor='black')\n",
    "axes[0, 0].set_ylabel('F1 Macro Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('F1 Macro - Validación', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "for i, v in enumerate(df_comparacion['F1 Macro Val']):\n",
    "    axes[0, 0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "axes[0, 1].bar(modelos, df_comparacion['F1 Micro Val'], alpha=0.8, color=colores, edgecolor='black')\n",
    "axes[0, 1].set_ylabel('F1 Micro Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('F1 Micro - Validación', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "for i, v in enumerate(df_comparacion['F1 Micro Val']):\n",
    "    axes[0, 1].text(i, v + 0.02, f'{v:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "axes[1, 0].bar(modelos, df_comparacion['AUC-PR Val'], alpha=0.8, color=colores, edgecolor='black')\n",
    "axes[1, 0].set_ylabel('AUC-PR Score', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('AUC-PR Macro - Validación', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "for i, v in enumerate(df_comparacion['AUC-PR Val']):\n",
    "    axes[1, 0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "axes[1, 1].bar(modelos, df_comparacion['Overfitting'], alpha=0.8, color=colores, edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Diferencia F1 (Train - Val)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('Indicador de Overfitting', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(df_comparacion['Overfitting']):\n",
    "    axes[1, 1].text(i, v + 0.005, f'{v:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_01_comparacion_metricas.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c36fd",
   "metadata": {},
   "source": [
    "## 5. Matrices de Confusión Comparativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = modelo_lr.predict(X_val_pca)\n",
    "y_pred_svm = modelo_svm.predict(X_val_pca)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val_img).permute(0, 3, 1, 2)\n",
    "y_val_tensor = torch.LongTensor(y_val)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "y_pred_cnn = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = modelo_cnn(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred_cnn.extend(predicted.cpu().numpy())\n",
    "\n",
    "y_pred_cnn = np.array(y_pred_cnn)\n",
    "\n",
    "cm_lr = confusion_matrix(y_val, y_pred_lr)\n",
    "cm_svm = confusion_matrix(y_val, y_pred_svm)\n",
    "cm_cnn = confusion_matrix(y_val, y_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', xticklabels=clases, yticklabels=clases,\n",
    "           cbar_kws={'label': 'Cantidad'}, linewidths=2, linecolor='black', ax=axes[0])\n",
    "axes[0].set_xlabel('Predicción', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Valor Real', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title(f'Logistic Regression\\nF1 Macro: {metricas_lr[\"f1_macro_val\"]:.4f}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Greens', xticklabels=clases, yticklabels=clases,\n",
    "           cbar_kws={'label': 'Cantidad'}, linewidths=2, linecolor='black', ax=axes[1])\n",
    "axes[1].set_xlabel('Predicción', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Valor Real', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title(f'SVM\\nF1 Macro: {metricas_svm[\"f1_macro_val\"]:.4f}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "\n",
    "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Reds', xticklabels=clases, yticklabels=clases,\n",
    "           cbar_kws={'label': 'Cantidad'}, linewidths=2, linecolor='black', ax=axes[2])\n",
    "axes[2].set_xlabel('Predicción', fontsize=11, fontweight='bold')\n",
    "axes[2].set_ylabel('Valor Real', fontsize=11, fontweight='bold')\n",
    "axes[2].set_title(f'CNN\\nF1 Macro: {metricas_cnn[\"f1_macro_val\"]:.4f}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_02_matrices_confusion.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13d4a3",
   "metadata": {},
   "source": [
    "## 6. Curvas de Pérdida del Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_cnn = historial_cnn['train_loss']\n",
    "val_loss_cnn = historial_cnn['val_loss']\n",
    "train_acc_cnn = historial_cnn['train_acc']\n",
    "val_acc_cnn = historial_cnn['val_acc']\n",
    "\n",
    "epochs = range(1, len(train_loss_cnn) + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].plot(epochs, train_loss_cnn, 'b-', linewidth=2, label='Train Loss', marker='o', markersize=3)\n",
    "axes[0].plot(epochs, val_loss_cnn, 'r-', linewidth=2, label='Validation Loss', marker='s', markersize=3)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Curvas de Pérdida - CNN', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11, loc='best')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(epochs, train_acc_cnn, 'b-', linewidth=2, label='Train Accuracy', marker='o', markersize=3)\n",
    "axes[1].plot(epochs, val_acc_cnn, 'r-', linewidth=2, label='Validation Accuracy', marker='s', markersize=3)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Curvas de Accuracy - CNN', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11, loc='best')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_03_curvas_cnn.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c10744",
   "metadata": {},
   "source": [
    "### 6.1 Análisis de Convergencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_epoch = np.argmin(val_loss_cnn) + 1\n",
    "mejor_val_loss = val_loss_cnn[mejor_epoch - 1]\n",
    "mejor_val_acc = val_acc_cnn[mejor_epoch - 1]\n",
    "\n",
    "diferencia_final = train_loss_cnn[-1] - val_loss_cnn[-1]\n",
    "\n",
    "df_convergencia = pd.DataFrame({\n",
    "    'Métrica': [\n",
    "        'Mejor Epoch',\n",
    "        'Mejor Val Loss',\n",
    "        'Mejor Val Accuracy',\n",
    "        'Loss Final Train',\n",
    "        'Loss Final Val',\n",
    "        'Diferencia Final (Train-Val)',\n",
    "        'Estado'\n",
    "    ],\n",
    "    'Valor': [\n",
    "        mejor_epoch,\n",
    "        f'{mejor_val_loss:.4f}',\n",
    "        f'{mejor_val_acc:.4f}',\n",
    "        f'{train_loss_cnn[-1]:.4f}',\n",
    "        f'{val_loss_cnn[-1]:.4f}',\n",
    "        f'{diferencia_final:.4f}',\n",
    "        'Overfitting leve' if diferencia_final > 0.1 else 'Buen ajuste'\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_convergencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529d5fb",
   "metadata": {},
   "source": [
    "## 7. Ranking de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranking = df_comparacion.copy()\n",
    "\n",
    "df_ranking['Rank F1 Macro'] = df_ranking['F1 Macro Val'].rank(ascending=False)\n",
    "df_ranking['Rank F1 Micro'] = df_ranking['F1 Micro Val'].rank(ascending=False)\n",
    "df_ranking['Rank AUC-PR'] = df_ranking['AUC-PR Val'].rank(ascending=False)\n",
    "df_ranking['Rank Overfitting'] = df_ranking['Overfitting'].rank(ascending=True)\n",
    "\n",
    "pesos = {'F1 Macro': 0.5, 'F1 Micro': 0.2, 'AUC-PR': 0.2, 'Overfitting': 0.1}\n",
    "\n",
    "df_ranking['Score Total'] = (\n",
    "    df_ranking['Rank F1 Macro'] * pesos['F1 Macro'] +\n",
    "    df_ranking['Rank F1 Micro'] * pesos['F1 Micro'] +\n",
    "    df_ranking['Rank AUC-PR'] * pesos['AUC-PR'] +\n",
    "    df_ranking['Rank Overfitting'] * pesos['Overfitting']\n",
    ")\n",
    "\n",
    "df_ranking['Ranking Final'] = df_ranking['Score Total'].rank(ascending=False).astype(int)\n",
    "df_ranking = df_ranking.sort_values('Ranking Final')\n",
    "\n",
    "df_ranking_display = df_ranking[[\n",
    "    'Ranking Final', 'Modelo', 'F1 Macro Val', 'F1 Micro Val', 'AUC-PR Val', 'Overfitting'\n",
    "]]\n",
    "\n",
    "df_ranking_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367cdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "modelos_ordenados = df_ranking['Modelo'].values\n",
    "scores = df_ranking['Score Total'].values\n",
    "\n",
    "colores_ranking = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "bars = ax.barh(modelos_ordenados, scores, alpha=0.8, color=colores_ranking, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Score Total Ponderado', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Ranking Final de Modelos (Menor es Mejor)', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (modelo, score, rank) in enumerate(zip(modelos_ordenados, scores, df_ranking['Ranking Final'])):\n",
    "    ax.text(score + 0.02, i, f'#{rank} - Score: {score:.3f}', \n",
    "           va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_04_ranking_modelos.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925277a4",
   "metadata": {},
   "source": [
    "## 8. Reportes de Clasificación Detallados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e57dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "reporte_lr = classification_report(y_val, y_pred_lr, target_names=clases, output_dict=True)\n",
    "reporte_svm = classification_report(y_val, y_pred_svm, target_names=clases, output_dict=True)\n",
    "reporte_cnn = classification_report(y_val, y_pred_cnn, target_names=clases, output_dict=True)\n",
    "\n",
    "df_reporte_lr = pd.DataFrame(reporte_lr).transpose().round(4)\n",
    "df_reporte_svm = pd.DataFrame(reporte_svm).transpose().round(4)\n",
    "df_reporte_cnn = pd.DataFrame(reporte_cnn).transpose().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reporte_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reporte_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf47fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reporte_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a48c16",
   "metadata": {},
   "source": [
    "### 8.1 Comparación por Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c754d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_por_clase = []\n",
    "\n",
    "for clase in clases:\n",
    "    metricas_por_clase.append({\n",
    "        'Clase': clase,\n",
    "        'LR Precision': reporte_lr[clase]['precision'],\n",
    "        'LR Recall': reporte_lr[clase]['recall'],\n",
    "        'LR F1': reporte_lr[clase]['f1-score'],\n",
    "        'SVM Precision': reporte_svm[clase]['precision'],\n",
    "        'SVM Recall': reporte_svm[clase]['recall'],\n",
    "        'SVM F1': reporte_svm[clase]['f1-score'],\n",
    "        'CNN Precision': reporte_cnn[clase]['precision'],\n",
    "        'CNN Recall': reporte_cnn[clase]['recall'],\n",
    "        'CNN F1': reporte_cnn[clase]['f1-score']\n",
    "    })\n",
    "\n",
    "df_metricas_clase = pd.DataFrame(metricas_por_clase).round(4)\n",
    "df_metricas_clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6551eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "x = np.arange(len(clases))\n",
    "ancho = 0.25\n",
    "\n",
    "axes[0].bar(x - ancho, [reporte_lr[c]['precision'] for c in clases], ancho, \n",
    "           label='LR', alpha=0.8, color='#3498db', edgecolor='black')\n",
    "axes[0].bar(x, [reporte_svm[c]['precision'] for c in clases], ancho, \n",
    "           label='SVM', alpha=0.8, color='#2ecc71', edgecolor='black')\n",
    "axes[0].bar(x + ancho, [reporte_cnn[c]['precision'] for c in clases], ancho, \n",
    "           label='CNN', alpha=0.8, color='#e74c3c', edgecolor='black')\n",
    "axes[0].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Precision por Clase', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(clases)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "axes[1].bar(x - ancho, [reporte_lr[c]['recall'] for c in clases], ancho, \n",
    "           label='LR', alpha=0.8, color='#3498db', edgecolor='black')\n",
    "axes[1].bar(x, [reporte_svm[c]['recall'] for c in clases], ancho, \n",
    "           label='SVM', alpha=0.8, color='#2ecc71', edgecolor='black')\n",
    "axes[1].bar(x + ancho, [reporte_cnn[c]['recall'] for c in clases], ancho, \n",
    "           label='CNN', alpha=0.8, color='#e74c3c', edgecolor='black')\n",
    "axes[1].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Recall', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Recall por Clase', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(clases)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "axes[2].bar(x - ancho, [reporte_lr[c]['f1-score'] for c in clases], ancho, \n",
    "           label='LR', alpha=0.8, color='#3498db', edgecolor='black')\n",
    "axes[2].bar(x, [reporte_svm[c]['f1-score'] for c in clases], ancho, \n",
    "           label='SVM', alpha=0.8, color='#2ecc71', edgecolor='black')\n",
    "axes[2].bar(x + ancho, [reporte_cnn[c]['f1-score'] for c in clases], ancho, \n",
    "           label='CNN', alpha=0.8, color='#e74c3c', edgecolor='black')\n",
    "axes[2].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title('F1-Score por Clase', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(clases)\n",
    "axes[2].legend(fontsize=10)\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "axes[2].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_05_metricas_por_clase.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294be8be",
   "metadata": {},
   "source": [
    "## 9. Selección del Modelo Ganador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_ganador = df_ranking.iloc[0]['Modelo']\n",
    "f1_macro_ganador = df_ranking.iloc[0]['F1 Macro Val']\n",
    "f1_micro_ganador = df_ranking.iloc[0]['F1 Micro Val']\n",
    "auc_pr_ganador = df_ranking.iloc[0]['AUC-PR Val']\n",
    "\n",
    "df_ganador = pd.DataFrame({\n",
    "    'Métrica': ['Modelo Seleccionado', 'F1 Macro Val', 'F1 Micro Val', 'AUC-PR Val', 'Ranking'],\n",
    "    'Valor': [modelo_ganador, f1_macro_ganador, f1_micro_ganador, auc_pr_ganador, 1]\n",
    "})\n",
    "\n",
    "df_ganador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9678e92",
   "metadata": {},
   "source": [
    "## 10. Conclusiones y Justificación Técnica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ef83d",
   "metadata": {},
   "source": [
    "### 10.1 Análisis de Resultados\n",
    "\n",
    "**Comparación de Modelos:**\n",
    "\n",
    "1. **Logistic Regression (Modelo Base):**\n",
    "   - Desempeño aceptable para un modelo simple\n",
    "   - Entrenamiento rápido y eficiente\n",
    "   - Limitado por la linealidad de las características PCA\n",
    "   - Mejor para deployment en recursos limitados\n",
    "\n",
    "2. **SVM (Modelo Avanzado 1):**\n",
    "   - Mejora sobre Logistic Regression mediante kernels no lineales\n",
    "   - Buena capacidad de generalización\n",
    "   - Tiempo de entrenamiento moderado\n",
    "   - Efectivo con características PCA de alta dimensión\n",
    "\n",
    "3. **CNN (Modelo Avanzado 2):**\n",
    "   - Aprende representaciones directamente de las imágenes\n",
    "   - Mayor capacidad de capturar patrones complejos\n",
    "   - Requiere más recursos computacionales\n",
    "   - Beneficio de GPU/CUDA para entrenamiento\n",
    "\n",
    "**Análisis de Convergencia (CNN):**\n",
    "- Las curvas de pérdida muestran convergencia clara\n",
    "- Pequeña diferencia entre train y validation indica buen ajuste\n",
    "- No se observa overfitting significativo\n",
    "- Early stopping implícito al guardar mejor modelo\n",
    "\n",
    "**Métricas Clave:**\n",
    "- **F1 Macro**: Métrica principal, importante para clases desbalanceadas\n",
    "- **AUC-PR**: Confirma capacidad discriminativa en todas las clases\n",
    "- **Matrices de Confusión**: Revelan patrones de confusión específicos por clase\n",
    "\n",
    "### 10.2 Selección del Modelo Ganador\n",
    "\n",
    "**Criterios de Selección:**\n",
    "1. F1 Macro (peso 50%): Métrica balanceada entre precision y recall\n",
    "2. F1 Micro (peso 20%): Desempeño global\n",
    "3. AUC-PR (peso 20%): Capacidad discriminativa\n",
    "4. Overfitting (peso 10%): Generalización\n",
    "\n",
    "**Modelo Seleccionado:** El modelo con mejor ranking combinado\n",
    "\n",
    "**Justificación Técnica:**\n",
    "- Mejor F1 Macro indica mejor manejo del desbalance de clases\n",
    "- AUC-PR alto confirma buena separación entre clases\n",
    "- Bajo overfitting garantiza generalización a datos nuevos\n",
    "- Matrices de confusión muestran menor número de clasificaciones erróneas\n",
    "\n",
    "### 10.3 Recomendaciones para Implementación\n",
    "\n",
    "**Para Producción:**\n",
    "1. Si recursos son limitados: Usar Logistic Regression o SVM\n",
    "2. Si se dispone de GPU: CNN ofrece mejor desempeño\n",
    "3. Implementar ensemble de los 3 modelos para mayor robustez\n",
    "\n",
    "**Monitoreo:**\n",
    "- Tracking de F1 Macro en producción\n",
    "- Detección de drift en distribución de clases\n",
    "- Reentrenamiento periódico con datos nuevos\n",
    "\n",
    "### 10.4 Limitaciones del Dataset\n",
    "\n",
    "1. **Tamaño:** Dataset relativamente pequeño (2,727 imágenes totales)\n",
    "2. **Desbalance:** Clase 'plastic' significativamente minoritaria\n",
    "3. **Variabilidad:** Limitada en condiciones de iluminación y fondos\n",
    "4. **Generalización:** Posible overfitting a condiciones específicas del dataset\n",
    "\n",
    "### 10.5 Trabajo Futuro\n",
    "\n",
    "**Mejoras Propuestas:**\n",
    "1. Aumentar dataset con más imágenes reales\n",
    "2. Transfer learning con modelos pre-entrenados (ResNet, EfficientNet)\n",
    "3. Técnicas de balanceo más sofisticadas (SMOTE para imágenes)\n",
    "4. Explorar arquitecturas más profundas (ResNet, DenseNet)\n",
    "5. Implementar data augmentation más agresivo\n",
    "6. Probar ensemble methods (voting, stacking)\n",
    "7. Optimización de hiperparámetros con Bayesian Optimization más extensiva\n",
    "\n",
    "**Validación Adicional:**\n",
    "- Test set independiente para validación final\n",
    "- Cross-validation estratificado más exhaustivo\n",
    "- Evaluación en condiciones reales de operación"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "06C_Machine_15S02_Proyecto03",
   "language": "python",
   "name": "06c_machine_15s02_proyecto03"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
