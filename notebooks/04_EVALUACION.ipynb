{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afb5dbe",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ec914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7921e7",
   "metadata": {},
   "source": [
    "## Configuración de rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7db18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_base = Path(r'e:\\06. Sexto Ciclo\\01. Machine Learning\\07. Workspace\\16S03. Proyecto 03\\P3-EcoSort')\n",
    "ruta_features = ruta_base / 'result' / 'features'\n",
    "ruta_modelos = ruta_base / 'result' / 'models'\n",
    "ruta_figuras = ruta_base / 'result' / 'figures'\n",
    "\n",
    "clases = ['general', 'paper', 'plastic']\n",
    "num_clases = len(clases)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c684ed",
   "metadata": {},
   "source": [
    "## 1. Carga de datos y modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233355f",
   "metadata": {},
   "source": [
    "### 1.1 Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = np.load(ruta_features / 'X_train_imagenes.npy')\n",
    "X_val_img = np.load(ruta_features / 'X_val_imagenes.npy')\n",
    "y_train = np.load(ruta_features / 'y_train.npy')\n",
    "y_val = np.load(ruta_features / 'y_val.npy')\n",
    "\n",
    "features_train_pca = np.load(ruta_features / 'features_train_pca.npy')\n",
    "features_val_pca = np.load(ruta_features / 'features_val_pca.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc36e60",
   "metadata": {},
   "source": [
    "### 1.2 Carga de modelos entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271de731",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lr = joblib.load(ruta_modelos / 'logistic_regression_model.pkl')\n",
    "modelo_svm = joblib.load(ruta_modelos / 'svm_model.pkl')\n",
    "\n",
    "class CNN_Clasificador(nn.Module):\n",
    "    def __init__(self, num_clases, dropout_rate=0.5):\n",
    "        super(CNN_Clasificador, self).__init__()\n",
    "        \n",
    "        self.capa_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(dropout_rate * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.capa_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(dropout_rate * 0.6)\n",
    "        )\n",
    "        \n",
    "        self.capa_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(dropout_rate * 0.7)\n",
    "        )\n",
    "        \n",
    "        self.capa_fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 16 * 16, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_clases)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.capa_conv1(x)\n",
    "        x = self.capa_conv2(x)\n",
    "        x = self.capa_conv3(x)\n",
    "        x = self.capa_fc(x)\n",
    "        return x\n",
    "\n",
    "params_cnn = joblib.load(ruta_modelos / 'cnn_params.pkl')\n",
    "modelo_cnn = CNN_Clasificador(num_clases, dropout_rate=params_cnn['dropout']).to(device)\n",
    "modelo_cnn.load_state_dict(torch.load(ruta_modelos / 'cnn_model.pth', map_location=device))\n",
    "modelo_cnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73939335",
   "metadata": {},
   "source": [
    "### 1.3 Carga de curvas de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1004de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "historial_train_lr = np.load(ruta_modelos / 'logistic_regression_train_loss.npy')\n",
    "historial_val_lr = np.load(ruta_modelos / 'logistic_regression_val_loss.npy')\n",
    "\n",
    "historial_train_svm = np.load(ruta_modelos / 'svm_train_loss.npy')\n",
    "historial_val_svm = np.load(ruta_modelos / 'svm_val_loss.npy')\n",
    "\n",
    "historial_train_cnn = np.load(ruta_modelos / 'cnn_train_loss.npy')\n",
    "historial_val_cnn = np.load(ruta_modelos / 'cnn_val_loss.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc640d3",
   "metadata": {},
   "source": [
    "## 2. Generación de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = modelo_lr.predict(features_val_pca)\n",
    "y_pred_proba_lr = modelo_lr.predict_proba(features_val_pca)\n",
    "\n",
    "y_pred_svm = modelo_svm.predict(features_val_pca)\n",
    "y_pred_proba_svm = modelo_svm.predict_proba(features_val_pca)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val_img).permute(0, 3, 1, 2)\n",
    "dataset_val = TensorDataset(X_val_tensor, torch.LongTensor(y_val))\n",
    "val_loader = DataLoader(dataset_val, batch_size=64, shuffle=False)\n",
    "\n",
    "y_pred_cnn = []\n",
    "y_pred_proba_cnn = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imagenes, _ in val_loader:\n",
    "        imagenes = imagenes.to(device)\n",
    "        salidas = modelo_cnn(imagenes)\n",
    "        probabilidades = torch.softmax(salidas, dim=1)\n",
    "        _, predicciones = torch.max(salidas, 1)\n",
    "        y_pred_cnn.extend(predicciones.cpu().numpy())\n",
    "        y_pred_proba_cnn.extend(probabilidades.cpu().numpy())\n",
    "\n",
    "y_pred_cnn = np.array(y_pred_cnn)\n",
    "y_pred_proba_cnn = np.array(y_pred_proba_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eec066",
   "metadata": {},
   "source": [
    "## 3. Comparación de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a473d3f",
   "metadata": {},
   "source": [
    "### 3.1 Cálculo de métricas completas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_todas_metricas(y_true, y_pred, y_pred_proba):\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "    f1_por_clase = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    y_true_bin = label_binarize(y_true, classes=[0, 1, 2])\n",
    "    auc_pr_scores = []\n",
    "    for i in range(num_clases):\n",
    "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_proba[:, i])\n",
    "        auc_pr_scores.append(auc(recall, precision))\n",
    "    auc_pr = np.mean(auc_pr_scores)\n",
    "    \n",
    "    return {\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_por_clase': f1_por_clase,\n",
    "        'auc_pr': auc_pr,\n",
    "        'auc_pr_por_clase': auc_pr_scores\n",
    "    }\n",
    "\n",
    "metricas_lr = calcular_todas_metricas(y_val, y_pred_lr, y_pred_proba_lr)\n",
    "metricas_svm = calcular_todas_metricas(y_val, y_pred_svm, y_pred_proba_svm)\n",
    "metricas_cnn = calcular_todas_metricas(y_val, y_pred_cnn, y_pred_proba_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d7f0a",
   "metadata": {},
   "source": [
    "### 3.2 Tabla comparativa de métricas globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_comparacion = pd.DataFrame({\n",
    "    'Modelo': ['Logistic Regression', 'SVM', 'CNN'],\n",
    "    'F1 Macro': [metricas_lr['f1_macro'], metricas_svm['f1_macro'], metricas_cnn['f1_macro']],\n",
    "    'F1 Micro': [metricas_lr['f1_micro'], metricas_svm['f1_micro'], metricas_cnn['f1_micro']],\n",
    "    'AUC-PR': [metricas_lr['auc_pr'], metricas_svm['auc_pr'], metricas_cnn['auc_pr']]\n",
    "}).round(4)\n",
    "\n",
    "tabla_comparacion['Ranking F1 Macro'] = tabla_comparacion['F1 Macro'].rank(ascending=False).astype(int)\n",
    "tabla_comparacion = tabla_comparacion.sort_values('F1 Macro', ascending=False)\n",
    "tabla_comparacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a8ac4",
   "metadata": {},
   "source": [
    "### 3.3 Tabla comparativa de F1 por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b80a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_f1_clases = pd.DataFrame({\n",
    "    'Clase': clases * 3,\n",
    "    'Modelo': ['Logistic Regression']*3 + ['SVM']*3 + ['CNN']*3,\n",
    "    'F1 Score': np.concatenate([metricas_lr['f1_por_clase'], metricas_svm['f1_por_clase'], metricas_cnn['f1_por_clase']])\n",
    "}).round(4)\n",
    "\n",
    "tabla_f1_clases_pivot = tabla_f1_clases.pivot(index='Clase', columns='Modelo', values='F1 Score')\n",
    "tabla_f1_clases_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3679ec",
   "metadata": {},
   "source": [
    "### 3.4 Visualización comparativa de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c36147",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "modelos_nombres = ['Logistic\\nRegression', 'SVM', 'CNN']\n",
    "f1_macro = [metricas_lr['f1_macro'], metricas_svm['f1_macro'], metricas_cnn['f1_macro']]\n",
    "colores = ['steelblue', 'coral', 'lightgreen']\n",
    "\n",
    "axes[0, 0].bar(modelos_nombres, f1_macro, color=colores, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "axes[0, 0].set_ylabel('F1 Macro', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('F1 Macro por modelo', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(f1_macro):\n",
    "    axes[0, 0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "f1_micro = [metricas_lr['f1_micro'], metricas_svm['f1_micro'], metricas_cnn['f1_micro']]\n",
    "axes[0, 1].bar(modelos_nombres, f1_micro, color=colores, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "axes[0, 1].set_ylabel('F1 Micro', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('F1 Micro por modelo', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(f1_micro):\n",
    "    axes[0, 1].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "auc_pr = [metricas_lr['auc_pr'], metricas_svm['auc_pr'], metricas_cnn['auc_pr']]\n",
    "axes[1, 0].bar(modelos_nombres, auc_pr, color=colores, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 0].set_ylabel('AUC-PR', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('AUC-PR por modelo', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(auc_pr):\n",
    "    axes[1, 0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "x_pos = np.arange(len(clases))\n",
    "ancho = 0.25\n",
    "axes[1, 1].bar(x_pos - ancho, metricas_lr['f1_por_clase'], ancho, label='LR', alpha=0.8, color='steelblue', edgecolor='black')\n",
    "axes[1, 1].bar(x_pos, metricas_svm['f1_por_clase'], ancho, label='SVM', alpha=0.8, color='coral', edgecolor='black')\n",
    "axes[1, 1].bar(x_pos + ancho, metricas_cnn['f1_por_clase'], ancho, label='CNN', alpha=0.8, color='lightgreen', edgecolor='black')\n",
    "axes[1, 1].set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Clase', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('F1 Score por clase y modelo', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels(clases)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Comparación exhaustiva de métricas entre modelos', fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_01_comparacion_metricas.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b856d96",
   "metadata": {},
   "source": [
    "## 4. Análisis de curvas de pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609de10",
   "metadata": {},
   "source": [
    "### 4.1 Visualización comparativa de curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd29c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "epochs_lr = range(1, len(historial_train_lr) + 1)\n",
    "axes[0].plot(epochs_lr, historial_train_lr, 'o-', label='Train', linewidth=2, markersize=4, color='steelblue')\n",
    "axes[0].plot(epochs_lr, historial_val_lr, 's-', label='Val', linewidth=2, markersize=4, color='coral')\n",
    "axes[0].set_xlabel('Iteración', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Loss', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Logistic Regression', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "epochs_svm = range(1, len(historial_train_svm) + 1)\n",
    "axes[1].plot(epochs_svm, historial_train_svm, 'o-', label='Train', linewidth=2, markersize=4, color='steelblue')\n",
    "axes[1].plot(epochs_svm, historial_val_svm, 's-', label='Val', linewidth=2, markersize=4, color='coral')\n",
    "axes[1].set_xlabel('Iteración', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Loss', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('SVM', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "epochs_cnn = range(1, len(historial_train_cnn) + 1)\n",
    "axes[2].plot(epochs_cnn, historial_train_cnn, 'o-', label='Train', linewidth=2, markersize=3, color='steelblue')\n",
    "axes[2].plot(epochs_cnn, historial_val_cnn, 's-', label='Val', linewidth=2, markersize=3, color='coral')\n",
    "axes[2].set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "axes[2].set_ylabel('Loss', fontsize=11, fontweight='bold')\n",
    "axes[2].set_title('CNN', fontsize=12, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Curvas de pérdida - Comparación entre modelos', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_02_curvas_perdida_comparacion.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ab038",
   "metadata": {},
   "source": [
    "### 4.2 Análisis de convergencia y overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc409439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_convergencia(train_loss, val_loss, nombre_modelo):\n",
    "    final_train_loss = train_loss[-1]\n",
    "    final_val_loss = val_loss[-1]\n",
    "    gap_loss = abs(final_train_loss - final_val_loss)\n",
    "    \n",
    "    convergio = final_train_loss < 0.1\n",
    "    overfitting = gap_loss > 0.1\n",
    "    underfitting = final_train_loss > 0.3 and final_val_loss > 0.3\n",
    "    \n",
    "    diagnostico = ''\n",
    "    if overfitting:\n",
    "        diagnostico = 'Overfitting detectado'\n",
    "    elif underfitting:\n",
    "        diagnostico = 'Underfitting detectado'\n",
    "    else:\n",
    "        diagnostico = 'Buen ajuste'\n",
    "    \n",
    "    return {\n",
    "        'Modelo': nombre_modelo,\n",
    "        'Train Loss final': final_train_loss,\n",
    "        'Val Loss final': final_val_loss,\n",
    "        'Gap Train-Val': gap_loss,\n",
    "        'Diagnóstico': diagnostico\n",
    "    }\n",
    "\n",
    "analisis_lr = analizar_convergencia(historial_train_lr, historial_val_lr, 'Logistic Regression')\n",
    "analisis_svm = analizar_convergencia(historial_train_svm, historial_val_svm, 'SVM')\n",
    "analisis_cnn = analizar_convergencia(historial_train_cnn, historial_val_cnn, 'CNN')\n",
    "\n",
    "tabla_convergencia = pd.DataFrame([analisis_lr, analisis_svm, analisis_cnn]).round(4)\n",
    "tabla_convergencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee61c5",
   "metadata": {},
   "source": [
    "## 5. Matrices de confusión comparativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "cm_lr = confusion_matrix(y_val, y_pred_lr)\n",
    "cm_lr_norm = cm_lr.astype('float') / cm_lr.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_lr_norm, annot=True, fmt='.3f', cmap='Blues', xticklabels=clases, yticklabels=clases, ax=axes[0], cbar_kws={'label': 'Proporción'})\n",
    "axes[0].set_xlabel('Predicción', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Verdadero', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Logistic Regression', fontsize=12, fontweight='bold')\n",
    "\n",
    "cm_svm = confusion_matrix(y_val, y_pred_svm)\n",
    "cm_svm_norm = cm_svm.astype('float') / cm_svm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_svm_norm, annot=True, fmt='.3f', cmap='Oranges', xticklabels=clases, yticklabels=clases, ax=axes[1], cbar_kws={'label': 'Proporción'})\n",
    "axes[1].set_xlabel('Predicción', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Verdadero', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('SVM', fontsize=12, fontweight='bold')\n",
    "\n",
    "cm_cnn = confusion_matrix(y_val, y_pred_cnn)\n",
    "cm_cnn_norm = cm_cnn.astype('float') / cm_cnn.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_cnn_norm, annot=True, fmt='.3f', cmap='Greens', xticklabels=clases, yticklabels=clases, ax=axes[2], cbar_kws={'label': 'Proporción'})\n",
    "axes[2].set_xlabel('Predicción', fontsize=11, fontweight='bold')\n",
    "axes[2].set_ylabel('Verdadero', fontsize=11, fontweight='bold')\n",
    "axes[2].set_title('CNN', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Matrices de confusión normalizadas - Comparación entre modelos', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_03_matrices_confusion_comparacion.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9bd72",
   "metadata": {},
   "source": [
    "## 6. Curvas Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_bin = label_binarize(y_val, classes=[0, 1, 2])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, clase in enumerate(clases):\n",
    "    precision_lr, recall_lr, _ = precision_recall_curve(y_val_bin[:, i], y_pred_proba_lr[:, i])\n",
    "    axes[0].plot(recall_lr, precision_lr, label=f'{clase} (AUC={metricas_lr[\"auc_pr_por_clase\"][i]:.3f})', linewidth=2)\n",
    "axes[0].set_xlabel('Recall', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Precision', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Logistic Regression', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "for i, clase in enumerate(clases):\n",
    "    precision_svm, recall_svm, _ = precision_recall_curve(y_val_bin[:, i], y_pred_proba_svm[:, i])\n",
    "    axes[1].plot(recall_svm, precision_svm, label=f'{clase} (AUC={metricas_svm[\"auc_pr_por_clase\"][i]:.3f})', linewidth=2)\n",
    "axes[1].set_xlabel('Recall', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Precision', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('SVM', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "for i, clase in enumerate(clases):\n",
    "    precision_cnn, recall_cnn, _ = precision_recall_curve(y_val_bin[:, i], y_pred_proba_cnn[:, i])\n",
    "    axes[2].plot(recall_cnn, precision_cnn, label=f'{clase} (AUC={metricas_cnn[\"auc_pr_por_clase\"][i]:.3f})', linewidth=2)\n",
    "axes[2].set_xlabel('Recall', fontsize=11, fontweight='bold')\n",
    "axes[2].set_ylabel('Precision', fontsize=11, fontweight='bold')\n",
    "axes[2].set_title('CNN', fontsize=12, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Curvas Precision-Recall por clase y modelo', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_04_precision_recall_curves.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f553b4",
   "metadata": {},
   "source": [
    "## 7. Ranking final de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f7651",
   "metadata": {},
   "outputs": [],
   "source": [
    "puntuaciones = []\n",
    "\n",
    "for nombre, metricas in [('Logistic Regression', metricas_lr), ('SVM', metricas_svm), ('CNN', metricas_cnn)]:\n",
    "    puntuacion_total = (\n",
    "        metricas['f1_macro'] * 0.5 +\n",
    "        metricas['f1_micro'] * 0.2 +\n",
    "        metricas['auc_pr'] * 0.3\n",
    "    )\n",
    "    puntuaciones.append({\n",
    "        'Modelo': nombre,\n",
    "        'F1 Macro': metricas['f1_macro'],\n",
    "        'F1 Micro': metricas['f1_micro'],\n",
    "        'AUC-PR': metricas['auc_pr'],\n",
    "        'Puntuación Total': puntuacion_total\n",
    "    })\n",
    "\n",
    "ranking_final = pd.DataFrame(puntuaciones).round(4)\n",
    "ranking_final = ranking_final.sort_values('Puntuación Total', ascending=False)\n",
    "ranking_final['Ranking'] = range(1, len(ranking_final) + 1)\n",
    "ranking_final = ranking_final[['Ranking', 'Modelo', 'F1 Macro', 'F1 Micro', 'AUC-PR', 'Puntuación Total']]\n",
    "ranking_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colores_ranking = ['gold', 'silver', '#CD7F32']\n",
    "bars = ax.barh(ranking_final['Modelo'], ranking_final['Puntuación Total'], color=colores_ranking, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Puntuación Total (50% F1 Macro + 20% F1 Micro + 30% AUC-PR)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Ranking Final de Modelos', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (idx, row) in enumerate(ranking_final.iterrows()):\n",
    "    ax.text(row['Puntuación Total'] + 0.02, i, f\"{row['Puntuación Total']:.4f}\", va='center', fontweight='bold', fontsize=11)\n",
    "    ax.text(0.02, i, f\"#{row['Ranking']}\", va='center', fontweight='bold', fontsize=12, color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ruta_figuras / '04_eval_05_ranking_final.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1c29e",
   "metadata": {},
   "source": [
    "## 8. Selección del modelo ganador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caaa0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_ganador = ranking_final.iloc[0]['Modelo']\n",
    "f1_ganador = ranking_final.iloc[0]['F1 Macro']\n",
    "puntuacion_ganador = ranking_final.iloc[0]['Puntuación Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389fcd7",
   "metadata": {},
   "source": [
    "### Justificación técnica de la selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36101088",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelo_ganador == 'CNN':\n",
    "    idx_ganador = 2\n",
    "    metricas_ganador = metricas_cnn\n",
    "    analisis_ganador = analisis_cnn\n",
    "elif modelo_ganador == 'SVM':\n",
    "    idx_ganador = 1\n",
    "    metricas_ganador = metricas_svm\n",
    "    analisis_ganador = analisis_svm\n",
    "else:\n",
    "    idx_ganador = 0\n",
    "    metricas_ganador = metricas_lr\n",
    "    analisis_ganador = analisis_lr\n",
    "\n",
    "reporte_ganador = pd.DataFrame({\n",
    "    'Aspecto': [\n",
    "        'Modelo seleccionado',\n",
    "        'F1 Macro',\n",
    "        'F1 Micro',\n",
    "        'AUC-PR',\n",
    "        'Puntuación total',\n",
    "        'Diagnóstico convergencia',\n",
    "        'Loss final validación',\n",
    "        'Gap Train-Val'\n",
    "    ],\n",
    "    'Valor': [\n",
    "        modelo_ganador,\n",
    "        f\"{metricas_ganador['f1_macro']:.4f}\",\n",
    "        f\"{metricas_ganador['f1_micro']:.4f}\",\n",
    "        f\"{metricas_ganador['auc_pr']:.4f}\",\n",
    "        f\"{puntuacion_ganador:.4f}\",\n",
    "        analisis_ganador['Diagnóstico'],\n",
    "        f\"{analisis_ganador['Val Loss final']:.4f}\",\n",
    "        f\"{analisis_ganador['Gap Train-Val']:.4f}\"\n",
    "    ]\n",
    "})\n",
    "reporte_ganador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0c833",
   "metadata": {},
   "source": [
    "## 9. Reporte de clasificación del modelo ganador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelo_ganador == 'CNN':\n",
    "    y_pred_ganador = y_pred_cnn\n",
    "elif modelo_ganador == 'SVM':\n",
    "    y_pred_ganador = y_pred_svm\n",
    "else:\n",
    "    y_pred_ganador = y_pred_lr\n",
    "\n",
    "reporte_clasificacion = classification_report(y_val, y_pred_ganador, target_names=clases, output_dict=True)\n",
    "df_reporte_clasificacion = pd.DataFrame(reporte_clasificacion).transpose().round(4)\n",
    "df_reporte_clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949afc8",
   "metadata": {},
   "source": [
    "## 10. Conclusiones y recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1995d7",
   "metadata": {},
   "source": [
    "### Conclusiones principales\n",
    "\n",
    "**1. Desempeño comparativo:**\n",
    "- Se evaluaron rigurosamente tres modelos: Logistic Regression (baseline), SVM y CNN\n",
    "- El ranking se basó en métricas robustas: F1 Macro (50%), F1 Micro (20%) y AUC-PR (30%)\n",
    "- Todos los modelos mostraron capacidad de clasificación en el problema de residuos\n",
    "\n",
    "**2. Análisis de convergencia:**\n",
    "- Las curvas de pérdida revelaron el comportamiento de entrenamiento de cada modelo\n",
    "- Se identificaron posibles casos de overfitting o underfitting mediante el gap train-val\n",
    "- La CNN mostró convergencia progresiva a lo largo de 50 epochs\n",
    "\n",
    "**3. Características del modelo ganador:**\n",
    "- Presentó el mejor balance entre precision y recall en todas las clases\n",
    "- Demostró robustez en métricas multiclase (F1 Macro)\n",
    "- Capacidad de generalización adecuada según análisis de validación\n",
    "\n",
    "**4. Análisis por clase:**\n",
    "- Se identificaron las clases con mejor y peor desempeño\n",
    "- Las matrices de confusión revelaron patrones de confusión entre clases específicas\n",
    "- Las curvas Precision-Recall mostraron el trade-off por clase\n",
    "\n",
    "### Recomendaciones para implementación\n",
    "\n",
    "**1. Despliegue en producción:**\n",
    "- Utilizar el modelo ganador para clasificación de residuos en tiempo real\n",
    "- Implementar sistema de confianza basado en probabilidades de predicción\n",
    "- Monitorear métricas en producción para detectar degradación del modelo\n",
    "\n",
    "**2. Mejoras futuras:**\n",
    "- Recolectar más datos de clases con menor desempeño\n",
    "- Explorar técnicas de ensemble combinando modelos\n",
    "- Implementar transfer learning con modelos preentrenados\n",
    "- Aumentar diversidad de datos con nuevas condiciones de captura\n",
    "\n",
    "**3. Limitaciones del dataset:**\n",
    "- El desempeño está condicionado a condiciones similares de iluminación y fondo\n",
    "- Puede requerir recalibración para nuevos tipos de residuos\n",
    "- La generalización depende de la variabilidad capturada en el entrenamiento\n",
    "\n",
    "**4. Consideraciones prácticas:**\n",
    "- Balance entre precisión del modelo y costo computacional\n",
    "- Evaluación de latencia para aplicaciones en tiempo real\n",
    "- Implementación de pipeline completo desde captura hasta clasificación"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "06C_Machine_15S02_Proyecto03",
   "language": "python",
   "name": "06c_machine_15s02_proyecto03"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
